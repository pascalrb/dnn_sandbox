{"cells":[{"cell_type":"markdown","metadata":{"id":"--Nu9FrPMO1G"},"source":["Modules:\n","* **pruned_layers.py**, contains the pruning of DNNs to reduce the storage of insignificant weight parameters by two methods: pruning by percentage and prune by standara deviation.\n","* **train_util.py**, includes the training process of DNNs with pruned connections.\n","* **quantize.py**, applies the quantization (weight sharing) part on the DNN to reduce the storage of weight parameters.\n","* **huffman_coding.py**, applies the Huffman coding onto the weight of DNNs to further compress the weight size.\n","\n","Files Created:\n","* **net_before_pruning.pt**, the weight parameters before applying pruning on DNN weight parameters.\n","* **net_after_pruning.pt**, the weight paramters after applying pruning on DNN weight parameters.\n","* **net_after_quantization.pt**, the weight parameters after applying quantization (weight sharing) on DNN weight parameters.\n","* **codebook_vgg16.npy**, the quantization codebook of each layer after applying quantization (weight sharing).\n","* **huffman_encoding.npy**, the encoding map of each item within the quantization codebook in the whole DNN architecture.\n","* **huffman_freq.npy**, the frequency map of each item within the quantization codebook in the whole DNN.\n","\n","This work uses VGG16_half, which is a down-scaled version of VGG16 using a width multiplier of 0.5. See the implementation in **vgg16.py** for more details."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24774,"status":"ok","timestamp":1698461994214,"user":{"displayName":"Pascal Bastien","userId":"01948231222556018374"},"user_tz":240},"id":"aokFavEMMO1H","outputId":"e65a88a6-1e43-482e-dc37-cb407b340d90","pycharm":{"is_executing":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Training on GPU...\n"]}],"source":["import os\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","# Change the current working directory to the Google drive folder for path to dataloader\n","#os.chdir('/content/drive/MyDrive/')\n","\n","from vgg16 import VGG16, VGG16_half\n","from train_util import train, finetune_after_prune, test\n","from quantize import quantize_whole_model\n","from huffman_coding import huffman_coding\n","from summary import summary\n","import torch\n","import numpy as np\n","from prune import prune\n","\n","import time\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","if device =='cuda':\n","    print(\"Training on GPU...\")\n","else:\n","    print(\"Training on CPU...\")\n"]},{"cell_type":"markdown","metadata":{"id":"fR6DZHgzMO1J"},"source":["### Full-precision model training"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5435,"status":"ok","timestamp":1698461999643,"user":{"displayName":"Pascal Bastien","userId":"01948231222556018374"},"user_tz":240},"id":"jvILJrncMO1J","pycharm":{"is_executing":false,"name":"#%%\n"}},"outputs":[],"source":["net = VGG16_half()\n","net = net.to(device)\n","\n","#net.load_state_dict(torch.load(\"net_before_pruning.pt\"))\n","\n","# Hyperparameters tuning\n","#train(net, epochs=10, batch_size=233, lr=0.00, reg=0.0)\n","#train(net, epochs=10, batch_size=128, lr=0.001, reg=0.01)  #73.25\n","#train(net, epochs=10, batch_size=128, lr=0.007, reg=0.01)  # 84.8\n","#train(net, epochs=10, batch_size=128, lr=0.009, reg=0.01)  # 84.9\n","#train(net, epochs=10, batch_size=128, lr=0.01, reg=0.01)   #85.07\n","#train(net, epochs=30, batch_size=128, lr=0.01, reg=0.01)   # 89.75\n","#train(net, epochs=45, batch_size=128, lr=0.01, reg=0.01)   # 90.52    <-- \n","#train(net, epochs=10, batch_size=128, lr=0.02, reg=0.01)   #83.6\n","#train(net, epochs=10, batch_size=128, lr=0.1, reg=0.01)    # 55.56\n","\n","#train(net, epochs=10, batch_size=128, lr=0.01, reg=0.0001) #82.0%\n","#train(net, epochs=10, batch_size=128, lr=0.01, reg=0.001)  #82.4\n","#train(net, epochs=10, batch_size=128, lr=0.01, reg=0.1)    #35.12\n","\n","#train(net, epochs=10, batch_size=128, lr=0.1, reg=0.0001)  #71.0%"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19373,"status":"ok","timestamp":1698462019007,"user":{"displayName":"Pascal Bastien","userId":"01948231222556018374"},"user_tz":240},"id":"g5WOIKzBMO1K","outputId":"316f482d-64dc-4f94-9103-38b0c90adc54"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading to GPU...\n","Files already downloaded and verified\n","Test Loss=0.3275, Test accuracy=90.5200\n"]}],"source":["# Loading the best weight paramters\n","if(torch.cuda.is_available()):\n","  net.load_state_dict(torch.load(\"net_before_pruning.pt\"))\n","  print('loading to GPU...')\n","else:\n","  net.load_state_dict(torch.load(\"net_before_pruning.pt\", map_location=torch.device('cpu')))\n","  print('loading to CPU...')\n","\n","test(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXCtOOshMO1K"},"outputs":[],"source":["print(\"-----Summary before pruning-----\")\n","summary(net)\n","print(\"-------------------------------\")"]},{"cell_type":"markdown","metadata":{"id":"N7b4_nTaMO1L"},"source":["### Pruning & Finetune with pruned connections"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5325,"status":"ok","timestamp":1698462024327,"user":{"displayName":"Pascal Bastien","userId":"01948231222556018374"},"user_tz":240},"id":"UbNwLmUJMO1L","outputId":"c8f41576-b4de-428c-cb67-4b7bf79c4299"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Test Loss=0.5701, Test accuracy=84.5000\n"]}],"source":["# Pruning by percentage or standard deviation clipping\n","#prune(net, method='percentage', q=0.25, s=0.75)        #25.00% sparsity | 84.5% accuracy\n","#prune(net, method='percentage', q=0.6680, s=0.75)      #66.79% sparsity | 83.24% accuracy\n","#prune(net, method='percentage', q=0.6681, s=0.75)      #66.80% sparsity | 83.15% accuracy\n","\n","#prune(net, method='std', q=0.25, s=0.046)    # 6.76% sparse, 90.52% acc\n","#prune(net, method='std', q=0.25, s=0.05)     # 7.31% sparse, 90.50% acc\n","#prune(net, method='std', q=0.25, s=0.1)      # 13.94% sparse, 90.46% acc\n","#prune(net, method='std', q=0.25, s=0.3)      # 35.92% sparse, 90.34% acc\n","#prune(net, method='std', q=0.25, s=0.5)      # 52.16% sparse, 89.76% acc\n","prune(net, method='std', q=0.25, s=0.75)      # 66.80% sparse, 84.50% acc\n","#prune(net, method='std', q=0.25, s=1.0)      # 76.99% sparse, 68.14% acc\n","#prune(net, method='std', q=0.25, s=1.5)      # 88.90% sparse, 18.60% acc\n","#prune(net, method='std', q=0.25, s=1.7)      # 91.65% sparse, 10.04% acc\n","#prune(net, method='std', q=0.25, s=2.0)      # 94.50% sparse, 10% acc\n","\n","test(net)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMYsAEos5DHN"},"outputs":[],"source":["print(\"\\n-----Summary after pruning-----\")\n","summary(net)\n","print(\"-------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXOlmvoVMO1L"},"outputs":[],"source":["# Finetuing model after pruning\n","#finetune_after_prune(net, epochs=50, batch_size=128, lr=0.001, reg=5e-5)\n","\n","#finetune_after_prune(net, epochs=10, batch_size=128, lr=0.01, reg=0.01)  #77.65 E?\n","\n","#finetune_after_prune(net, epochs=35, batch_size=128, lr=0.0001, reg=0.01)  #90.64 E23\n","#finetune_after_prune(net, epochs=35, batch_size=128, lr=0.0005, reg=0.01)  #89.52 E8\n","#finetune_after_prune(net, epochs=35, batch_size=128, lr=0.001, reg=0.01)   #88.31 E5   \n","#finetune_after_prune(net, epochs=35, batch_size=128, lr=0.005, reg=0.01)   #83.36 E22\n","#finetune_after_prune(net, epochs=45, batch_size=128, lr=0.01, reg=0.01)    #79.12 E34\n","#finetune_after_prune(net, epochs=35, batch_size=128, lr=0.05, reg=0.01)    #50.64 E10, dropped to 12 @E34\n","#finetune_after_prune(net, epochs=35, batch_size=128, lr=0.1, reg=0.01)     #\n","\n","\n","#print(\"-----Summary After Finetuning (After Pruning) -----\")\n","#summary(net)\n","#print(\"-------------------------------\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4599,"status":"ok","timestamp":1698462028921,"user":{"displayName":"Pascal Bastien","userId":"01948231222556018374"},"user_tz":240},"id":"1XIvXztRMO1M","outputId":"3df6a7ac-b3b2-47a5-9dd3-f3abb8c54887"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading to GPU...\n","Files already downloaded and verified\n","Test Loss=0.3470, Test accuracy=90.6400\n"]}],"source":["# Loading the best weight paramters\n","if(torch.cuda.is_available()):\n","  net.load_state_dict(torch.load(\"net_after_pruning.pt\"))\n","  print('loading to GPU...')\n","else:\n","  net.load_state_dict(torch.load(\"net_after_pruning.pt\", map_location=torch.device('cpu')))\n","  print('loading to CPU...')\n","\n","# Predict using the pruned and finetuned model\n","test(net)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8WLtKxVoMO1N"},"source":["### Quantization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2Sigu_lMO1N"},"outputs":[],"source":["centers = quantize_whole_model(net, bits=4)\n","torch.save(net.state_dict(), \"net_after_quantization.pt\")\n","np.save(\"codebook_vgg16.npy\", centers)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lreozXfjMO1O"},"outputs":[],"source":["#centers = quantize_whole_model(net, bits=2)  #25.17%\n","#centers = quantize_whole_model(net, bits=3)  #87.18%\n","#centers = quantize_whole_model(net, bits=4)  #90.12%\n","#centers = quantize_whole_model(net, bits=5)  #90.43%\n","#centers = quantize_whole_model(net, bits=8)  #90.63%\n","\n","#if(torch.cuda.is_available()):\n","#  net.load_state_dict(torch.load(\"net_after_quantization.pt\"))\n","#  print('loading to GPU...')\n","#else:\n","#  net.load_state_dict(torch.load(\"net_after_quantization.pt\", map_location=torch.device('cpu')))\n","#  print('loading to CPU...')\n","\n","\n","test(net, is_quantized=True, centers=centers)\n","\n","print(\"-----Summary After Test After Quantization -----\")\n","summary(net)\n","print(\"-------------------------------\")\n"]},{"cell_type":"markdown","metadata":{"id":"7IGlhgwYMO1O"},"source":["### Huffman Coding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hazCmasgMO1O"},"outputs":[],"source":["frequency_map, encoding_map = huffman_coding(net, centers)\n","np.save(\"huffman_encoding\", encoding_map)\n","np.save(\"huffman_freq\", frequency_map)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":0}
